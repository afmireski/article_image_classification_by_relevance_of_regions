# Importa libs Ãºteis para avaliaÃ§Ã£o dos modelos
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

from mytypes import ModelMetrics

def show_predict_infos(y, predict, title="", cmap="Blues", show_plots=True):
    """
    Calcula e exibe mÃ©tricas de avaliaÃ§Ã£o de modelos de classificaÃ§Ã£o.
    
    Args:
        y: Labels verdadeiros
        predict: PrediÃ§Ãµes do modelo
        title: TÃ­tulo para os grÃ¡ficos
        cmap: Mapa de cores para a matriz de confusÃ£o
        show_plots: Se True, exibe matriz de confusÃ£o. Se False, apenas calcula mÃ©tricas
        
    Returns:
        tuple: (accuracy, f1, recall, precision)
    """
    # Mostra a matriz de confusÃ£o apenas se solicitado
    if show_plots:
        show_confusion_matrix(y, predict, title, cmap)

    # Calcula e mostra as mÃ©tricas de avaliaÃ§Ã£o
    # A acurÃ¡cia Ã© a proporÃ§Ã£o de prediÃ§Ãµes corretas sobre o total de prediÃ§Ãµes
    accuracy = accuracy_score(y, predict)
    accuracy_percent = accuracy * 100
    
    if show_plots:
        print(f"A acurÃ¡cia no conjunto de testes: {accuracy_percent:.2f}%")

    # O recall Ã© a proporÃ§Ã£o de prediÃ§Ãµes corretas sobre o total de instÃ¢ncias de uma classe
    recall = recall_score(y, predict, average="macro")
    recall_percent = recall * 100
    
    if show_plots:
        print(f"A recall no conjunto de testes: {recall_percent:.2f}%")

    # A precisÃ£o Ã© a proporÃ§Ã£o de prediÃ§Ãµes corretas sobre o total de prediÃ§Ãµes de uma classe
    precision = precision_score(y, predict, average="macro")
    precision_percent = precision * 100
    
    if show_plots:
        print(f"A precision no conjunto de testes: {precision_percent:.2f}%")

    # A F1 Ã© a mÃ©dia harmÃ´nica entre a precisÃ£o e o recall
    f1 = f1_score(y, predict, average="macro")
    f1_percent = f1 * 100
    
    if show_plots:
        print(f"A F1 no conjunto de testes: {f1_percent:.2f}%")

        # Mostra um relatÃ³rio com as mÃ©tricas de classificaÃ§Ã£o por classe e as mÃ©tricas calculadas sobre o conjunto todo.
        print("\nRelatÃ³rio de ClassificaÃ§Ã£o")
        print(classification_report(y, predict))

    return accuracy, f1, recall, precision
    
def show_confusion_matrix(y, predict, title="", cmap="Blues", verbose=False, save_dir='results/confusion_matrixs'):
    import os
    
    # Cria a matriz de confusÃ£o
    ConfusionMatrixDisplay.from_predictions(y, predict, colorbar=False, cmap=cmap)
    
    # Adiciona tÃ­tulo se fornecido
    if len(title) > 0:
        plt.title(f"Matriz de ConfusÃ£o {title}")
    plt.xlabel("RÃ³tulo Previsto")
    plt.ylabel("RÃ³tulo Real")
    
    # Salva a matriz de confusÃ£o se um tÃ­tulo foi fornecido
    if len(title) > 0:
        # Cria o diretÃ³rio se nÃ£o existir
        os.makedirs(save_dir, exist_ok=True)
        
        # Gera nome do arquivo baseado no tÃ­tulo
        filename = title.lower().replace(" ", "_").replace("-", "_").replace("+", "_")
        filename = "".join(c for c in filename if c.isalnum() or c == "_")  # Remove caracteres especiais
        filepath = os.path.join(save_dir, f"{filename}_confusion_matrix.png")
        
        # Salva a figura
        plt.savefig(filepath, dpi=300, bbox_inches='tight', pad_inches=0.1)
        if verbose:
            print(f"ðŸ’¾ Matriz de confusÃ£o salva em: {filepath}")
    
    # Mostra a matriz apenas se verbose for True
    if verbose:
        plt.show()

def show_metrics(metrics: ModelMetrics, title=""):
    """
    Exibe mÃ©tricas de avaliaÃ§Ã£o de modelos de classificaÃ§Ã£o.
    
    Args:
        metrics: Tupla com as mÃ©tricas (accuracy, f1, recall, precision)
        title: TÃ­tulo para exibiÃ§Ã£o
    """
    accuracy, f1, recall, precision = metrics

    print("-" * 40)
    print(f"MÃ©tricas {title}:")
    print(f"   ðŸ“Š AcurÃ¡cia: {accuracy*100:.4f}%")
    print(f"   ðŸ“Š F1: {f1*100:.4f}%")
    print(f"   ðŸ“Š Recall: {recall*100:.4f}%")
    print(f"   ðŸ“Š Precision: {precision*100:.4f}%")
    print("-" * 40)